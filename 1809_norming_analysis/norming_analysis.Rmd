---
title: "Analysis of norming study (Sept 2018)"
author: '[Guillermo Montero-Melis](http://www.biling.su.se/montero_melis_guillermo)'
date: '`r as.character(format(Sys.Date(), format="%d/%m/%Y"))`'
output:
  html_document:
    depth: 2
    number_sections: yes
    theme: default
    toc: yes
  pdf_document:
    number_sections: yes
    toc: yes
  word_document:
    toc: yes
---

Introduction
============

This report summarizes the results of a set of norms we collected about English
and Swedish verbs regarding their arm/leg relatedness. All of the norms were
collected from L1 Swedish--L2 English speakers. Additionally, we carried out
a translation task for the (L2) English verbs, where we asked Swedish speakers
to translate them into Swedish.

The data collection took place on two occasions: June and September 2018.


Set up workspace
================

```{r setup, include=FALSE}
library(knitr)
library(ggplot2)
library(GGally)
library(dplyr)
library(tidyr)
library(readr)  # Improves the base functions for reading data files.
library(lme4)
knitr::opts_chunk$set(echo = TRUE, fig.height = 3.5)
```


```{r}
# load convenience functions
source("../Rfunctions/load_or_fit_fnc.R")
# some parameters
ggpairs_he <- 4.5  # default height for ggpairs plots
```


```{r, include = TRUE}
## load data files
# verb norming English
bias_en_l <- read.csv("data_verb-bias_L2eng.csv", fileEncoding = "UTF-8")
head(bias_en_l)
# verb norming Swedish
bias_sw_l <- read.csv("data_verb-bias_L1swe.csv", fileEncoding = "UTF-8")
head(bias_sw_l)
# verb comprehension/understanding
# compr <- read.csv(".csv",
#                   fileEncoding = "UTF-8")
# lextale task
# scored
lext <- read.csv("data_lextale_scored.csv", fileEncoding = "UTF-8")
head(lext)
# raw
lext_raw <- read.csv("data_lextale_raw.csv", fileEncoding = "UTF-8")
head(lext_raw)
# participant info
ppt <- read.csv("participant_info.csv", fileEncoding = "UTF-8")
head(ppt)
```


```{r}
# # In free translation task, consider translations scored as -99 (=unclear) as
# # incorrect (=0):
# und_free$score_unsimplified <- und_free$score  # keep copy of original variable
# und_free[und_free$score == -99, "score"] <- 0
```



Descriptives of data sets
================

What follows are some numbers to get a quick idea of the data sets. A fuller
description is found in the Appendices.

**English verbs**

- Number of unique participants who rated English verbs:
`r length(unique(bias_en_l$participant))`
- Number of unique English verbs that were rated:
`r length(unique(bias_en_l$verb))`
- NB: Not all participants rated all verbs (see Appendices)!

**Swedish verbs**

- Number of unique participants who rated Swedish verbs:
`r length(unique(bias_sw_l$participant))`
- Number of unique Swedish verbs that were rated:
`r length(unique(bias_sw_l$verb))`
- NB: I am pretty sure that all these participants rated all Swedish verbs...



Verb norming task: L2 English
==================================

The data from the verb norming task look like this:

```{r}
kable(head(bias_en_l[, 3:8]))
```

We have ratings for
`r length(unique(bias_en_l$verb))`
verbs, which we have collected on two different occasions. That means that
some verbs have been rated by more participants than others (see Appendix
for details), but this is not something we will worry about at first.


## Verb bias

For each verb, we can compute a single measure of *arm-minus-leg bias* (we call
it simply *bias*) by substracting the mean leg-relatedness rating from the mean
arm-relatedness rating for each verb, obtaining:

```{r}
bias_en <- bias_en_l %>%
  group_by(verb, category, rated_category) %>%
  summarise(rating = mean(rating),
            nObs = n()) %>%
  spread(rated_category, rating) %>%  # reshape to wide format for correlation plot
  mutate(bias = Arm - Leg)
kable(head(bias_en))
```

- A positive bias score (bias > 0) indicates bias towards arm-relatedness (max 6)
- A negative bias score (bias < 0) indicates bias towards leg-relatedness (min -6)
- A bias score = 0 indicates absence of either bias

```{r}
# order factor levels of verbs depending on their bias (for plotting)
ordered_verbs_bias_en <- as.character(pull(bias_en[order(bias_en$bias), ], verb))
bias_en$verb <- factor(bias_en$verb, levels = ordered_verbs_bias_en)
```


```{r, fig.height = 12}
ggplot(bias_en, aes(x = verb, y = bias, colour = category)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  theme(axis.text.x = element_text(size = 5)) +
  coord_flip() +
  ggtitle("Mean arm/leg bias of verbs")
```

The figure shows that the bias was generally stronger for the verbs we had
categorized as arm verbs than for those we thought of as leg verbs.

This can be shown even clearer if we just consider the size of the bias in
the expected direction, so now a negative bias constitutes a bias in the
"wrong" direction (e.g., an arm bias for a supposedly leg-related verb).
The following plot shows this:

```{r}
# We add a bias column that changes the sign for leg verbs, so that bias
# is expressed with respect to the expected direction of the bias for a verb
bias_en$bias_absol <- bias_en$bias
bias_en[bias_en$category == "leg", "bias_absol"] <- - bias_en[bias_en$category == "leg", "bias"]
ggplot(bias_en, aes(x = category, y = bias_absol, colour = category)) + 
  geom_boxplot() +
  ylab("Size of bias in predicted direction") +
  ggtitle("Size of congruent bias of English verbs")
```

Among the English verbs, `r sum(bias_en$bias_absol < 0)` had opposite bias
to what was expected:

```{r}
kable(bias_en[bias_en$bias_absol < 0, ])
```

To scuff means to "Scrape or brush the surface of (a shoe or other object) 
against something" (OED).
But participants seemed not to know the verb very well and assume it had some
arm-related meaning.

To dash means (OED):

1. Run or travel somewhere in a great hurry.
2. Strike or fling (something) somewhere with great force, especially so as to
have a destructive effect; hurl.

In the second sense it is considered a synonym of, among others,
*hurl, smash, crash, slam, throw, toss*, all of which are hand-related, so it
is in fact understandable that it had a arm/hand bias

```{r}
# Save the dataframe containing verb biases (`bias_en`) to disk:
write.csv(bias_en, "verb-bias_en_mean.csv", row.names = FALSE, fileEncoding = "UTF-8")
```



## Cut-off at bias = 3

Somewhat arbitrarily, we could say that a bias of 3 in the expected direction
constitutes an acceptable cut-off point to select a verb for the study.
There are 
`r sum(with(bias_en, bias_absol >= 3 & category == "arm"))`
arm verbs (out of `r sum(with(bias_en, category == "arm"))`) that satisfy this condition,
but only
`r sum(with(bias_en, bias_absol >= 3 & category == "leg"))`
leg verbs (out of
`r sum(with(bias_en, category == "leg"))`) that qualify.

Here are the leg verbs that have a clear bias:

```{r, fig.height = 5}
ggplot(bias_en[with(bias_en, bias_absol >= 3 & category == "leg"), ],
       aes(x = verb, y = bias)) +
  geom_point() +
  theme(axis.text.x = element_text(size = 6)) +
  coord_flip() +
  ggtitle("English leg verbs with strongest leg bias")
```


## Spread of ratings

Above we have only considered the mean rating for each verb (averaged across
participants).
But how much spread was there in the ratings from individual participants?

```{r}
bias_spread_en <- bias_en_l %>%
  select(participant, verb:rating) %>%
  spread(rated_category, rating) %>%
  mutate(bias = Arm - Leg)
# order verbs according to bias
bias_spread_en$verb <- factor(bias_spread_en$verb, levels = ordered_verbs_bias_en)
```


```{r, fig.height = 12}
ggplot(bias_spread_en, aes(x = verb, y = bias, colour = category)) +
  geom_hline(yintercept = 0) +
  stat_summary(fun.data = "mean_cl_boot") +
  geom_point(alpha = .4) +
  ylab("Verb bias") + 
  coord_flip() +
  ggtitle("Variability around mean arm/leg bias of English verbs")
```

What this figure shows is that the average bias for a verb can still hide some
important individual differences.
For instance, the leg verb *kneel* had a fairly strong leg bias of
`r round(bias_en[bias_en$verb == "kneel", ]$bias, 1)`
and still there was one participant who rated it as completely arm-biased
(bias = 6).

Some of these data points might simply be due to participants getting the 
scales mixed up, but probably not all of these data points came about in this
way:
Consider the supposedly leg verbs *tread* and *bounce*.
For the latter, one could imagine how a participant made associations with 
*bouncing a ball*, in which case the verb *to bounce* naturally becomes 
arm-related).

Finally, note also the many ratings of verbs as having no bias (verb bias = 0).
These may be the result of participants not knowing a verb meaning,
a matter to which we now turn.



Verb norming task: L1 Swedish
=============================

The data from the Swedish verb norming task look like this:

```{r}
kable(head(bias_sw_l[, 3:8]))
```

We have ratings for
`r length(unique(bias_sw_l$verb))`
verbs, all of which were collected in Sept 2018. We had
`r length(unique(bias_sw_l$participant))`
native Swedish speakers who provided the ratings.



## Verb bias

For each verb, we can compute a single measure of *arm-minus-leg bias* (we call
it simply *bias*) by substracting the mean leg-relatedness rating from the mean
arm-relatedness rating for each verb, obtaining:

```{r}
bias_sw <- bias_sw_l %>%
  group_by(verb, category, rated_category) %>%
  summarise(rating = mean(rating)) %>%
  spread(rated_category, rating) %>%  # reshape to wide format for correlation plot
  mutate(bias = Arm - Leg)
kable(head(bias_sw))
```

- A positive bias score (bias > 0) indicates bias towards arm-relatedness (max 6)
- A negative bias score (bias < 0) indicates bias towards leg-relatedness (min -6)
- A bias score = 0 indicates absence of either bias

```{r}
# order factor levels of verbs depending on their bias (for plotting)
ordered_verbs_bias_sw <- as.character(pull(bias_sw[order(bias_sw$bias), ], verb))
bias_sw$verb <- factor(bias_sw$verb, levels = ordered_verbs_bias_sw)
```


```{r, fig.height = 12}
ggplot(bias_sw, aes(x = verb, y = bias, colour = category)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  theme(axis.text.x = element_text(size = 5)) +
  coord_flip() +
  ggtitle("Mean arm/leg bias of Swedish verbs")
```

The figure shows that the bias was generally stronger for the verbs we had
categorized as arm verbs than for those we thought of as leg verbs.

This can be shown even clearer if we just consider the size of the bias in
the expected direction, so a negative bias now constitutes a bias in the 
"wrong" direction (e.g., an arm bias for a supposedly leg-related verb).
The following plot shows this:

```{r}
# We add a bias column that changes the sign for leg verbs, so that bias
# is expressed with respect to the expected direction of the bias for a verb
bias_sw$bias_absol <- bias_sw$bias
bias_sw[bias_sw$category == "leg", "bias_absol"] <- - bias_sw[bias_sw$category == "leg", "bias"]
ggplot(bias_sw, aes(x = category, y = bias_absol, colour = category)) + 
  geom_boxplot() +
  ylab("Size of bias in predicted direction") +
  ggtitle("Size of congruent bias of Swedish verbs")
```

Among the Swedish verbs, `r sum(bias_sw$bias_absol < 0)` had opposite
bias to what was expected:

```{r}
kable(bias_sw[bias_sw$bias_absol < 0, ])
```

All of these verbs are leg-related.

```{r}
# Save the dataframe containing verb biases (`bias_sw`) to disk:
write.csv(bias_sw, "verb-bias_sw_mean.csv", row.names = FALSE, fileEncoding = "UTF-8")
```



## Cut-off at bias = 3

Somewhat arbitrarily, we could say that a bias of 3 in the expected direction
constitutes an acceptable cut-off point to select a verb for the study.
There are 
`r sum(with(bias_sw, bias_absol >= 3 & category == "arm"))`
arm verbs (out of `r sum(with(bias_sw, category == "arm"))`) that satisfy this condition,
but only
`r sum(with(bias_sw, bias_absol >= 3 & category == "leg"))`
leg verbs (out of
`r sum(with(bias_sw, category == "leg"))`) that qualify.

Here are the leg verbs that have a clear bias:

```{r, fig.height = 5}
ggplot(bias_sw[with(bias_sw, bias_absol >= 3 & category == "leg"), ],
       aes(x = verb, y = bias)) +
  geom_point() +
  theme(axis.text.x = element_text(size = 6)) +
  coord_flip() +
  ggtitle("Swedish leg verbs with strongest leg bias")
```


## Spread of ratings

Above we have only considered the mean rating for each verb (averaged across
participants).
But how much spread was there in the ratings from individual participants?

```{r}
bias_spread_sw <- bias_sw_l %>%
  select(participant, verb:rating) %>%
  spread(rated_category, rating) %>%
  mutate(bias = Arm - Leg)
# order verbs according to bias
bias_spread_sw$verb <- factor(bias_spread_sw$verb, levels = ordered_verbs_bias_sw)
```


```{r, fig.height = 12}
ggplot(bias_spread_sw, aes(x = verb, y = bias, colour = category)) +
  geom_hline(yintercept = 0) +
  stat_summary(fun.data = "mean_cl_boot") +
  geom_point(alpha = .4) +
  ylab("Verb bias") + 
  coord_flip() +
  ggtitle("Variability around mean arm/leg bias of Swedish verbs")
```

What this figure shows is that the average bias for a verb can still hide some
important individual differences.
Some of these data points might simply be due to participants getting the 
scales mixed up, but probably not all of these data points came about in this
way.

Note also the some ratings have no bias (verb bias = 0). This is unlikely to
be due to Swedish speakers not knowing the verbs (since they were native 
speakers).


L2 verb comprehension task
======================

In the norming study in Sept 2018, 12 Swedish participants carried out a
comprehension task for the L2 English verbs: they had to translate the English
verbs to Swedish. The translations were then scored as either correct or
incorrect by two Swedish native speakers (see 
`norming_1809_analysis/scoring_translation-task.Rmd` for details about inter-
rater agreement).


The data set and some processing
--------------------------------

The final data set (after resolving disagreements between raters) looks like
this:

```{r}
compr <- read.csv("data_translations_scored.csv", fileEncoding = "UTF-8",
                  stringsAsFactors = FALSE)
kable(head(compr %>% select(participant:cognate)))
```

Note that some verbs haven't any verb_category assigned:

```{r}
# Note that some verbs haven't any verb_category assigned:
unique(compr %>% select(expName, verb, verb_category:in_orig)) %>% 
  filter(is.na(verb_category)) %>% kable
```

These are verbs for which we collected data in June, but which we subsequently
excluded because they were unsuitable for several reasons (ambiguous, unknown,
low bias...). So simply remove them from the data set. (We will remove
`r sum(is.na(compr$verb_category))` observations.)

```{r}
compr <- compr[! is.na(compr$verb_category), ]
```



The coding scheme was:

- 1 = Correct translation
- 0 = Incorrect translation
- 0.5 = Partly correct but underspecified (e.g., 'gå' for 'lumber')
- -99 = Undecided

Here's a table over how much each of the scoring occurred:

```{r}
table(compr$score)
```

We will remove scores of -99 (treat them as NAs) and leave the rest as they are.

```{r}
compr <- compr[! compr$score == -99, ]
```


Create a data frame with the mean score per verb (expressed as percentage of
number of responses provided)

```{r}
# Create a data frame with the mean ratings
(compr_vbs <- compr %>%
  group_by(verb, verb_category, cognate_bin, cognate) %>%
  summarise(sumScore = sum(score),
            N = n(),
            Score = sumScore / N)) %>%
  head %>% kable
```


Verb comprehension by word type
-------------------------------

Show Scores by verb type:

```{r}
ggplot(compr_vbs, aes(x = verb_category, y = Score, colour = verb_category)) +
  geom_boxplot() + ylab("Proportion correct translations")
```

Leg verbs were less well understood than arm verbs.

Let's look at binned scores:

```{r}
compr_vbs$binnedScore <- cut(compr_vbs$Score, seq(0, 1, .25), right = FALSE, 
                             include.lowest = TRUE)
with(compr_vbs, table(binnedScore, verb_category))
```

We should probably only include verbs that have at least a mean score of 50%
correct translations.


Choice of target verbs
======================

We need to take into account:

- Verb bias (L2 Eng and Swe)
- Verb comprehension (L2 Eng)
- Whether it's a translation equivalent (Eng-to-Swe)
- Cognate status (L2 Engl)
- Other frequency and word length measures


English verbs
-------------

The two most important factors are verb bias and whether it's understood
by Swedish speakers. Let's combine that information:

```{r}
# Add info about verb bias to the comprehension scores
compr_vbs <- left_join(compr_vbs, bias_en %>% ungroup() %>% select(verb, bias, bias_absol))
kable(head(compr_vbs))
```

And plot it:

```{r}
ggplot(compr_vbs, aes(x = Score, y = bias_absol, colour = verb_category)) +
  geom_point() +
  geom_vline(xintercept = .5, linetype = "dashed") +
  geom_hline(yintercept = 3, linetype = "dashed") +
  ylab("Verb bias in coherent direction") +
  xlab("Proportion correct translations") +
  ggtitle("Bias and translation accuracy for L2 English verbs")
```

Ideally we want to keep only verbs that are in the upper right quadrant. These
are verbs that both were translated correctly at least 50% of the time and
elicited a bias of at least 3 in the expected direction.


Let's also add frequency measures and number of phonemes:

```{r}
# Add info about verb frequency
(en_vbs_freq <- read.csv("en_verbs_various_measures.csv")) %>% head %>% kable
compr_vbs <- left_join(compr_vbs, en_vbs_freq)
kable(head(compr_vbs))
```

### First selection of L2 English verbs

Let's take a look at them:

```{r}
# Subset verbs that meet criteria, but relax bias to catch a verb that is right
# below 3 (it's trek, with bias 2.92, and switch, with bias 2.97)
select_en <- compr_vbs %>% 
  filter(Score >= .5 & bias_absol >= 2.9)
```

```{r, fig.height = 6, fig.width = 10}
ggplot(select_en, aes(x = Score, y = bias_absol, colour = verb_category,
                      label = verb)) +
  geom_text() +
  ylab("Verb bias in coherent direction") +
  xlab("Proportion correct translations") +
  ggtitle("First selection of L2 English verbs")
```

How many of each type are there?

```{r}
table(select_en$verb_category)
```


### Can we come up to 40 leg verbs?

We are short of 3 leg verbs to have 10 quadruples per block (which would
require 40 distinct verbs).

To see if we can find a few more leg verbs, we can relax our requirements
somewhat. So let's take a look at verbs in the upper left and lower right
quadrants from the figure above.

Verbs with high leg bias but poor translation accuracy, or the opposite, verbs
with high translation accuracyl but low leg bias:

```{r, fig.height = 5}
compr_vbs %>% 
  filter(verb_category == "leg" &
           ((Score > .5 & bias_absol < 3) | (Score < .5 & bias_absol > 3))) %>%
  ggplot(aes(x = Score, y = bias_absol, label = verb)) +
  geom_text() +
  geom_vline(xintercept = .5, linetype = "dashed") +
  geom_hline(yintercept = 3, linetype = "dashed") +
  xlim(0,1) + ylim(0,6) +
  ylab("Verb bias in coherent direction") +
  xlab("Proportion correct translations") 
```

We can include the following three verbs: dance, stride and trample.
*Creep* and *stamp*, though well understood when asking about the verb, can
easily be associated with their noun homonyms.


```{r}
select_en <- rbind(select_en, 
                   compr_vbs[compr_vbs$verb %in% c("stride", "dance", "trample"),])
kable(tail(select_en))
```


### Select strongest 40 verbs in each category

This is how many verbs we have:

```{r}
select_en %>% group_by(verb_category) %>% summarise(N = n())
```

We have 40 leg words, but need to reduce the list of arm verbs.


Let's raise both the bias and comprhension thesholds somewhat
(choose thresholds based on visualization above):

```{r}
en_arm_verbs <- select_en %>%
  filter(verb_category == "arm" & bias_absol > 4 & Score > .7)
```

Now we are down to the following `r nrow(en_arm_verbs)` arm verbs:

```{r, fig.height = 6, fig.width = 10}
ggplot(en_arm_verbs, aes(x = Score, y = bias_absol, label = verb)) +
  geom_point() +
  geom_text() +
  ylab("Verb bias in coherent direction") +
  xlab("Proportion correct translations") +
  ggtitle("Best L2 English arm verbs")
```

Since one difference between arm/leg verbs was that the former had fewer phonemes,
we can exclude among those that have fewest phonemes. There are quite a few.

```{r}
en_arm_verbs %>%
  ungroup() %>%
  arrange(nb_of_phonemes, -SUBTL_US_zipf, bias_absol, Score) %>%
  select(verb, nb_of_phonemes, SUBTL_US_zipf, bias_absol, Score) %>%
  filter(nb_of_phonemes == 3) %>%
  kable
```

They are all quite similar, so just remove 4 based on gut feeling. Remove:
stir, wash, hack, cut

```{r}
en_arm_verbs <- en_arm_verbs %>% 
  filter(! verb %in% c("stir", "wash", "hack", "cut"))
```


Reduce the selection of the final verbs to the best arm words:

```{r}
select_en_fin <- select_en %>% 
  filter(verb %in% en_arm_verbs$verb | verb_category == "leg")
```



### Check other variables


#### Frequency

We use the Zipf-frequency measure in SUBTLEX as suggested by Brysbaert et al. [REF]

US Corpus looks good

```{r}
ggplot(select_en_fin, aes(x = verb_category, y = SUBTL_US_zipf)) + geom_boxplot() +
  ggtitle("Frequency in SUBTLEX-US")
```

```{r}
select_en_fin %>% group_by(verb_category) %>%
    summarise(M_US_zipf = mean(SUBTL_US_zipf),
              SD_US_zipf = sd(SUBTL_US_zipf),
              min_US_zipf = min(SUBTL_US_zipf),
              max_US_zipf = max(SUBTL_US_zipf)) %>%
  kable
```

UK Corpus looks good

```{r}
ggplot(select_en_fin, aes(x = verb_category, y = SUBTL_UK_zipf)) + geom_boxplot() +
  ggtitle("Frequency in SUBTLEX-UK")
```

```{r}
select_en_fin %>% group_by(verb_category) %>%
    summarise(M_UK_zipf = mean(SUBTL_UK_zipf),
              SD_UK_zipf = sd(SUBTL_UK_zipf),
              min_UK_zipf = min(SUBTL_UK_zipf),
              max_UK_zipf = max(SUBTL_UK_zipf)) %>%
  kable
```


#### Word length

Summary of number of letters:

```{r}
select_en_fin$nbLetters <- nchar(select_en_fin$verb)
with(select_en_fin, addmargins(table(nbLetters, verb_category)))
select_en_fin %>% group_by(verb_category) %>%
  summarise(M_letters = mean(nbLetters),
            SD_letters = sd(nbLetters),
            min_letters = min(nbLetters),
            max_letters = max(nbLetters)) %>%
  kable
```

Looks good.

What are the longest words?

```{r}
select_en_fin %>%
  ungroup() %>%
  arrange(-nbLetters) %>%
  select(- c(cognate_bin : binnedScore, bias_absol, SUBTL_US_fpmw : SUBTL_UK_zipf)) %>%
  head %>%
  kable
```


And the shortest?

```{r}
select_en_fin %>%
  ungroup() %>%
  arrange(-nbLetters) %>%
  select(- c(cognate_bin : binnedScore, bias_absol, SUBTL_US_fpmw : SUBTL_UK_zipf)) %>%
  tail %>%
  kable
```


#### Phoneme length


```{r}
ggplot(select_en_fin, aes(x = verb_category, y = nb_of_phonemes)) + geom_boxplot() +
  ggtitle("Number of phonemes")
```

```{r}
select_en_fin %>% group_by(verb_category) %>%
    summarise(M_nb_phonemes = mean(nb_of_phonemes),
              SD_nb_phonemes = sd(nb_of_phonemes),
              min_nb_phonemes = min(nb_of_phonemes),
              max_nb_phonemes = max(nb_of_phonemes)) %>%
  kable
```

Those differ a bit more.

Wilcoxon test 
([see here](http://www.sthda.com/english/wiki/unpaired-two-samples-wilcoxon-test-in-r))

```{r}
wilcox.test(nb_of_phonemes ~ verb_category, data = select_en_fin)
```

This differs from the original, but we prioritize having bias and comprehension
which are they key aspects for the study. Note that since we are testing the
interaction, this difference cannot introduce a bias that spuriously leads
to a false positive.


#### Cognate status

Table of cognate status

```{r}
with(select_en_fin, addmargins(table(cognate_bin, verb_category)))
```

Looks okay



### Save to disk final selection

```{r}
select_en_fin %>%
  arrange(verb_category, verb) %>%
  select(verb : cognate, Score, bias) %T>%  # Note the tee operator https://www.datacamp.com/community/tutorials/pipe-r-tutorial
  kable() %>%
  write.csv("english-targets_with-info.csv", row.names = FALSE,
            fileEncoding = "UTF-8")
```


```{r}
select_en_fin_out <- select_en_fin %>%
  ungroup() %>%
  arrange(verb_category, verb) %>%
  select(type = verb_category, verb)  # for compatibility with functions in other scripts
head(select_en_fin_out); tail(select_en_fin_out)
# Save to disk (two different destinations):
write.csv(select_en_fin_out, "english-targets.csv", row.names = FALSE,
          fileEncoding = "UTF-8")
write.csv(select_en_fin_out, "../exp-scripts_psychopy/replication_pilot_1810/stimuli/english-targets.csv",
          row.names = FALSE, fileEncoding = "UTF-8")
```



Swedish verbs
-------------

```{r}
cutoff_swe <- 2.5
```

We now run the same analyses but for the L1 Swedish norms we collected.
In Swedish it is simpler because for now we only have two sources:

- Verb bias (arm vs leg): we want verbs with a bias of at least `r cutoff_swe`.
- Other word-related measures (frequency, etc.)



### Add frequency measures and do a first comparison of arm vs leg verbs

A short excursion to add the frequency information (from Swedish SubtLex corpus,
kindly provided by Jeroen van Paridon). The frequency counts come from a corpus
of more than a 100 million words extracted from a database of Swedish subtitles
(101,270,590 word tokens based on the data file I have).

```{r}
# Retrieve frequency data for words and lemmas
freq_word_sw <- read_tsv(
  "frequency_measures/filtered_word_unigram_freqs_sv.tsv", col_names = FALSE
  ) %>%
  rename(word = X1, word_freq = X2)
freq_lemma_sw <- read_tsv(
  "frequency_measures/filtered_lemma_unigram_freqs_sv.tsv", col_names = FALSE
  ) %>%
  rename(lemma = X1, lemma_freq = X2)
head(freq_word_sw)
head(freq_lemma_sw)
```

```{r}
# We will trust the parts-of-speech (POS) tagged lemmatization, even if some of
# the POS assignments are probably off. We hope that they are in the right 
# ballpark.
# Divide "lemma" column into the actual lemma and the POS tag (using regular
# expressions (regex), see https://www.regular-expressions.info/rlanguage.html)
freq_lemma_sw$lemma_true <- sub("(.*)_([a-z]*)$", "\\1", freq_lemma_sw$lemma)
freq_lemma_sw$POS <- sub("(.*)_([a-z]*)$", "\\2", freq_lemma_sw$lemma)
head(freq_lemma_sw)
# This is mostly what we want, but it also results in some inaccuracies because
# not all lemmas actually have a tag.
# To illustrate, consider the unique values in the POS column:
unique(freq_lemma_sw$POS)
# Some of them are clearly not POS tags, but the verbs themselves!
# But it's a pain to sort this out, so let's just ignore those exceptional cases
# and focus on lemmas tagged as verbs:
freq_verblemmas_sw <- freq_lemma_sw %>% filter(POS == "verb")
```

Sanity checks:

```{r}
# Sanity check: is any of our Swedish verbs not present in freq_verblemmas_sw or
# freq_word_sw?
sum(! bias_sw$verb %in% freq_verblemmas_sw$lemma_true)  # none is missing
sum(! bias_sw$verb %in% freq_word_sw$word)  # none is missing
```

Join the verb list with frequency measures:

```{r}
bias_sw <- bias_sw %>% 
  left_join(freq_word_sw, by = c("verb" = "word")) %>%
  left_join(freq_verblemmas_sw %>% select(lemma_freq, lemma_true),
            by = c("verb" = "lemma_true"))
# order factor levels of verbs depending on their bias (for plotting)
bias_sw$verb <- factor(bias_sw$verb, levels = ordered_verbs_bias_sw)
```

Log-frequencies probably make more sense

```{r}
bias_sw$word_logfreq <- log10(bias_sw$word_freq)
bias_sw$lemma_logfreq <- log10(bias_sw$lemma_freq)
bias_sw %>% head %>% kable
```

As a further check, do lemma and word frequency correlate?

```{r}
ggplot(bias_sw, aes(x = word_freq, y = lemma_freq)) + geom_point()
ggplot(bias_sw, aes(x = word_logfreq, y = lemma_logfreq)) + geom_point()
```

Note that the log-transformed frequency makes much more sense and that the
correlations are pretty high, which is good.

The following plot shows the actual verbs

```{r}
ggplot(bias_sw, aes(x = word_logfreq, y = lemma_logfreq, label = verb)) +
  geom_text()
```


Compare the log frequency of arm and leg words:

```{r}
ggplot(bias_sw, aes(x = category, y = word_logfreq, colour = category)) +
  geom_boxplot()
ggplot(bias_sw, aes(x = category, y = lemma_logfreq, colour = category)) +
  geom_boxplot()
```

Their frequencies overlap, but arm verbs tend to be more frequent than leg verbs.


Show the verbs with the lowest lemma frequencies:

```{r}
bias_sw[order(bias_sw$lemma_logfreq)[1:10], ] %>% kable
```


What is the relation between the absolute bias (i.e., size of congruent bias)
and (log) lemma frequency?


```{r}
ggplot(bias_sw, aes(x = lemma_logfreq, y = bias_absol, colour = category)) +
  geom_point() +
  geom_hline(aes(yintercept = cutoff_swe)) +
  geom_vline(aes(xintercept = 1))
```

We want to basically only have verbs in the upper right quadrant.




### Verb bias cut-off at `r cutoff_swe`

We take cut-off point at `r cutoff_swe`, so that we have some leeway later for
filtering out verbs as a function of frequency and other measures:

There are 
`r sum(with(bias_sw, bias_absol >= cutoff_swe & category == "arm"))` arm verbs 
(out of `r sum(with(bias_sw, category == "arm"))`) that satisfy this condition,
but only `r sum(with(bias_sw, bias_absol >= cutoff_swe & category == "leg"))` 
leg verbs (out of `r sum(with(bias_sw, category == "leg"))`) that qualify.

Here are the leg verbs that have a bias >= `r cutoff_swe`:

```{r, fig.height = 5}
ggplot(bias_sw[with(bias_sw, bias_absol >= cutoff_swe & category == "leg"), ],
       aes(x = verb, y = bias)) +
  geom_point() +
  theme(axis.text.x = element_text(size = 6)) +
  coord_flip() +
  ggtitle("Swedish leg verbs with strongest leg bias")
```


### First selection of Swedish verbs for further norming

We will need to match arm and leg verbs with respect to the variables Shebani
and Pulvermüller (2013) matched (see their Table 1 on p.225). So we better take
as large a selection as possible so that we can later match them and still have
enough verbs left.

For now we want the following:

1) Verbs with maximal arm or leg bias
2) Verbs that are not too infrequent


Filter out verbs with *both* lemma and word log-frequency below 1 (i.e., raw
frequencies below 10).
Then filter out verbs with a bias lower than 2.5.

```{r}
select_sw <- bias_sw %>% 
  filter(! (word_logfreq < 1 & lemma_logfreq < 1)) %>%
  filter(bias_absol >= cutoff_swe)
```


How many of each type are there?

```{r}
table(select_sw$category)
```


We select all leg verbs and 65 arm verbs, for a total of 120 verbs.

```{r}
# 66 Swedish arm verbs with strongest arm bias:
sw_top64_arm <- as.character(pull(select_sw[order(- select_sw$bias), ], verb))[1:65]
select_sw <- select_sw %>%
  filter(category == "leg" | verb %in% sw_top64_arm)
```

Here are the verbs we have selected now:

```{r, fig.height = 10}
ggplot(select_sw, aes(x = verb, y = bias, colour = category)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  theme(axis.text.x = element_text(size = 5)) +
  coord_flip() +
  ggtitle("Mean leg/arm bias of selection of Swedish verbs")
```


```{r}
ggplot(select_sw, aes(x = category, y = bias_absol, colour = category)) + 
  geom_boxplot() +
  ylab("Size of bias in predicted direction") +
  ggtitle("Size of congruent bias of selected Swedish verbs")
```


And here are their lemma frequencies

```{r}
ggplot(select_sw, aes(x = category, y = lemma_logfreq, colour = category)) + 
  geom_boxplot() +
  ylab("Size of bias in predicted direction") +
  ggtitle("Log lemma frequency of selected Swedish verbs")
```


Save this list to disk for further norming:


```{r}
# for alphabetic ordering of verbs to work (if a factor, it orders factor values)
select_sw$verb <- as.character(select_sw$verb)  
select_sw %>%
  ungroup() %>%
  arrange(category, verb) %>%
  select(verb, category) %>%
  write.csv("swe-targets_for-norming.csv", row.names = FALSE, fileEncoding = "UTF-8")
```



### Check other variables

We go through the variables listed in Shebani and Pulvermüller (2013, p.225 
Table 1):



#### Word length (Number of letters)

Summary of number of letters:

```{r}
select_sw$nbLetters <- nchar(select_sw$verb)
with(select_sw, addmargins(table(nbLetters, category)))
select_sw %>% 
  group_by(category) %>%
  summarise(M_letters = mean(nbLetters),
            SD_letters = sd(nbLetters),
            min_letters = min(nbLetters),
            max_letters = max(nbLetters)) %>%
  kable
```

Looks good.

What are the longest words?

```{r}
select_sw %>%
  ungroup() %>%
  arrange(-nbLetters) %>%
  # select(- c(cognate_bin : binnedScore, bias_absol, SUBTL_US_fpmw : SUBTL_UK_zipf)) %>%
  head(8) %>%
  kable
```


And the shortest?

```{r}
select_sw %>%
  ungroup() %>%
  arrange(-nbLetters) %>%
  # select(- c(cognate_bin : binnedScore, bias_absol, SUBTL_US_fpmw : SUBTL_UK_zipf)) %>%
  tail(8) %>%
  kable
```


#### Number of phonemes


#### Word frequency (really: lemma frequency)


#### Bigram frequency


#### Trigram frequency


#### Grammatical ambiguity (?)

Can we obtain a measure of this?


#### Valence


#### Arousal


#### Imageability


#### Visual relatedness


#### Body relatedness


#### Action relatedness




### Save to disk final selection

See corresponding section for English verbs...




Appendices
==========

Full list of normed L2 verbs (June and September)
------------------------------------------------

List of all normed L2 English verbs, sorted after bias, and adding translation
scores if available:

```{r}
bias_en %>% 
  left_join(compr_vbs %>% select(verb, Score)) %>%
  arrange(bias, verb) %>%
  kable
```

The column nObs (=number of observations) shows how many participants rated
a given verb.

Note that we had verbs rated for their arm- vs leg-relatedness on two separate
occasions: in the pilot study in June, and in the norming study in September
2018. Most of the verbs were rated on both occasions, but some were just
rated either in June or in September.

```{r}
vbs_junsep <- sort(unique(bias_en_l$verb[bias_en_l$verb_normed == "june+sept"]))
vbs_jun <- sort(unique(bias_en_l$verb[bias_en_l$verb_normed == "june"]))
vbs_sep <- sort(unique(bias_en_l$verb[bias_en_l$verb_normed == "sept"]))
```


Verbs rated **both in June and in September**:

`r vbs_junsep`


Verbs rated **in June only**:

`r vbs_jun`


Verbs rated **in September only**:

`r vbs_sep`
