---
title: "Selection of Swedish target verbs"
author: '[Guillermo Montero-Melis](https://www.mpi.nl/people/montero-melis-guillermo)'
date: '`r as.character(format(Sys.Date(), format="%d/%m/%Y"))`'
output:
  html_document:
    depth: 2
    number_sections: yes
    theme: default
    toc: yes
---



Introduction
============

This script selects the Swedish verbs that will be used in the replication of
Shebani and Pulvermüller (2014, Cortex, henceforth SP14).
Because we had to control for the same variables as in the original study,
we needed to collect quite a lot of norms for the Swedish verbs.

NB:
There is a previous report in this gitrepo 
("1809_norming_analysis/norming_analysis.Rmd") that does many of the pre-selection
on which this report builds. But it was getting so long (among others because it
contained norms for Swedish and English verbs) that I prefered to start a new
report/script that focuses precisely on the selection of Swedish target verbs.


Goal
====

We want to select an equal amount of leg- and arm-related verbs that differ
maximally in their arm/leg relatedness, while they are matched for the
following variables:

- Number of letters
- Number of phonemes
- Word frequency 
- Grammatical ambiguity 
- Lemma frequency 
- Bigram frequency 
- Trigram frequency 
- Valence 
- Arousal
- Imageability 

Note that SP14 mention three additional variables in Table 1, p.225:
Visual relatedness, body relatedness, and action relatedness. We checked with
the correspondin author, Friedemann Pulvermüller, and it turns out these
measures were actually redundant, so he acknowledged we did not need to collect
them (see correspondence from Tue 2019-04-30, 10:19 PM; subject "Short query
about word norms in Shebani & Pulvermüller (2013)").



Set up workspace
================

Libraries
---------

```{r setup, include=TRUE}
library(knitr)
library(ggplot2)
# library(GGally)
library(dplyr)
library(tidyr)
library(readr)  # Improves the base functions for reading data files.
# library(lme4)
knitr::opts_chunk$set(echo = TRUE, fig.height = 3.5)
```

Data import and processing
---------------------

We want to sequentially integrate all relevant variables into the same dataframe.

### Arm/leg bias

```{r, include = TRUE}
## load data files
# Arm/leg verb bias Swedish (note this already contains average ratings, for
# details about how it was generated, see "norming_analysis.Rmd")
bias <- read_csv("verb-bias_sw_mean.csv")
head(bias)
```

### Norms (imageability, valence and arousal ratings)

```{r}
# verb norming Swedish: imageability, valence and arousal ratings
# (this processed file is created in "norming_imageability-etc_preprocess.R")
norms <- read_csv("data_verb-norming_swe_ratings.csv")
head(norms)
```


Among the verbs in `norms` we have arm verbs, leg verbs and control verbs.
Let's add that info:

```{r}
# arm/leg words
norms <- left_join(norms, bias %>% select(Word = verb, Category = category))
# the rest are control words
norms[is.na(norms$Category), "Category"] <- "control"
norms$Category <- factor(norms$Category, levels = c("arm", "leg", "control"))
head(norms)
```

We only want mean ratings:

```{r}
norms_mean <- norms %>%
  filter(Category != "control") %>% 
  group_by(Word, Category, Task) %>%
  summarise(Rating = mean(Rating))
```


### Combine norms with bias ratings into single `stim` file

It's easiest to have a wide data set where each column is one property of
the stimuli:

```{r}
norms_mean <- spread(norms_mean, Task, Rating)
head(norms_mean, 4)
```



```{r}
stim <- left_join(norms_mean, bias %>% select(Word = verb, Arm : bias_absol))
head(stim, 4)
```



### Word frequency

The different frequency measures were obtained from Jeroen vP's big Sub2vec 
Swedish corpus with his help:

The frequency of the actual word form (infinitives):

```{r}
freq_word <- read_tsv(
  "frequency_measures/filtered_word_unigram_freqs_sv.tsv", col_names = FALSE
  ) %>%
  rename(Word = X1, word_freq = X2) %>%
  mutate(word_logfreq = log10(word_freq))
head(freq_word)
```


Add to `stim`

```{r}
stim <- left_join(stim, freq_word %>% select(-word_freq))
head(stim, 4) %>% kable
```



### Lemma frequency

The frequency of the lemma word forms can be computed in different ways
(see Brysbaert and New, 2009, p.982-984). I define it here as the (logged) sum
of the frequencies of all forms of the word of the same part-of-speech (POS).
This means that for the verb *play* I would add the frequencies of play (used as
a verb), plays (used as a verb), played, playing; but not of play/plays used as
nouns (singular and plural).
Of course I will rely on the automatic POS tagging for this, which in itself
might contain some errors.

```{r}
freq_lemma <- read_tsv(
  "frequency_measures/filtered_lemma_unigram_freqs_sv.tsv", col_names = FALSE
  ) %>%
  rename(lemma = X1, lemma_freq = X2)
head(freq_lemma)
```


Parts-of-speech (POS) tagging

```{r}
# We will trust the parts-of-speech (POS) tagged lemmatization, even if some of
# the POS assignments are probably off. We hope that they are in the right 
# ballpark.
# Divide "lemma" column into the actual lemma and the POS tag (using regular
# expressions (regex), see https://www.regular-expressions.info/rlanguage.html)
freq_lemma$lemma_true <- sub("(.*)_([a-z]*)$", "\\1", freq_lemma$lemma)
freq_lemma$POS <- sub("(.*)_([a-z]*)$", "\\2", freq_lemma$lemma)
head(freq_lemma)
# This is mostly what we want, but it also results in some inaccuracies because
# not all lemmas actually have a tag.
# To illustrate, consider some of the unique values in the POS column:
unique(freq_lemma$POS)[1:12]
# Some of them are clearly not POS tags, but the verbs themselves!
# But it's a pain to sort this out, so let's just ignore those exceptional cases
# and focus on lemmas tagged as verbs. Hopefully this will only remove some
# evenly distributed noise.
freq_verblemmas <- freq_lemma %>% filter(POS == "verb")
```


Add that info to our growing `stim` data frame:

```{r}
stim <- stim %>%
  left_join(freq_verblemmas %>%
              mutate(lemma_logfreq = log10(lemma_freq)) %>%
              select(Word = lemma_true, lemma_logfreq))
head(stim, 4) %>% kable
```



### Grammatical ambiguity (of the lemma)

We define grammatical ambiguity as 1 minus the proportion of verb occurrences
of a lemma divided by all occurrences of the same lemma (tagged as any POS).
Thus we obtain a score between 0 and 1:

- A score close to zero tells us that there is little ambiguity, i.e. the word
almost always appears as a verb
- A score close to 1 would tell us that there is maximal ambiguity, i.e. the
word hardly ever occurs as a verb.
- Note that this number only tells us about relative occurrence (proportion of
occurrences) so it doesn't take into account if a word is frequent or not.

Note that this is not giving us the grammatical ambiguity of the wordfrom itself
(e.g., "play") but of its lemma. This is a limitation imposed by the nature of
the corpus being used (see correspondence with Jeroen van Paridon, especially
emails from or around Mon 05-06, 3:00 PM, Subject: "automatically collecting
psycholinguistic features of Swedish words from corpora?")


```{r}
# Select only verb occurrences
gramm_ambig <- freq_lemma %>%
  filter(POS == "verb") %>% select(lemma_true, lemma_freq) %>%
  # join with the overall frequency
  left_join(freq_lemma %>%
              group_by(lemma_true) %>%
              summarise(overall_freq = sum(lemma_freq))
            ) %>%
  mutate(POS_ambig = 1 - lemma_freq / overall_freq)
head(gramm_ambig)
```

Add info to our growing `stim` data frame:

```{r}
stim <- stim %>%
  left_join(gramm_ambig %>%
              select(Word = lemma_true, POS_ambig))
head(stim, 4) %>% kable
```



### Bi- and trigram frequency ($log_{10}$ frequency)

These two measures per word are computed from raw bigram frequencies in the
corpus. The script that does the computation is 
`1809_norming_analysis/bi-trigram_freqs.R`.

```{r}
# Bigram frequency
bigrams <- read_csv("frequency_measures/word_bigram_freqs_sv.csv")
head(bigrams)
# Trigram frequency
trigrams <- read_csv("frequency_measures/word_trigram_freqs_sv.csv")
head(trigrams)
```


Add that info to our growing `stim` data frame:

```{r}
stim <- stim %>%
  left_join(bigrams) %>%
  left_join(trigrams)
head(stim, 4) %>% kable
```


### Number of letters

Add number of letters:

```{r}
stim$nletters <- nchar(stim$Word)
```



### Number of phonemes



### Variable names to lower case

Only for consistency and stylstic purism:

```{r}
stim <- stim %>% rename(word = Word, category = Category, arm = Arm, leg = Leg,
                        pos_ambig = POS_ambig)
```



Verb selection
==============

Our constraints are as follows. We want:

- An equal amount of arm and leg verbs
(there are `r sum(stim$category == "arm")` arm verbs and 
`r sum(stim$category == "leg")` leg verbs among the 120 verbs in the list)
- The number of verbs per category has to be a multiple of 4 (preferably)
- The arm and leg bias in each category should be maximized
- The verbs should be matched across categories for all the other variables


A quick look at arm/leg bias
----------------------------

How well does our general arm/leg bias measure (arm-relatedness minus 
leg-relatedness rating) capture the individual arm and leg ratings?

```{r}
ggplot(stim, aes(x = arm, y = leg, colour = category)) +
  geom_point(alpha = .5) +
  geom_hline(yintercept = 4, linetype = "dashed") +
  geom_vline(xintercept = 4, linetype = "dashed") +
  xlab("arm-relatedness") +
  ylab("leg-relatedness")
```

The verbs cluster well within each category and there are no cases where they
receive a high rating from the opposite category.

Then let's simplify the dataframe and leave only the absolute bias measure:

```{r}
stim <- stim %>% 
  select(- c("arm", "leg", "bias")) %>%
  rename(arm_leg_bias = bias_absol)
```


Going about selecting verbs
--------------------------

We will use a bit of a trial-and-error strategy. For that it's useful to create
a function that plots the category comparison (arm vs legs) for each of the
variables and carries out t-tests for each comparison.

From wide to long format:

```{r}
# From current wide format
kable(head(stim))
# to long format
stiml <- gather(stim, var, value, arousal : nletters)
kable(head(stiml))
kable(tail(stiml))
```


```{r}
# Choose a meaninful order for the features (rather than alphabetical)
unique(stiml$var)
stiml$var <- factor(
  stiml$var, 
  levels = c("arm_leg_bias", "arousal", "imageability", "valence", "nletters",
             "word_logfreq", "lemma_logfreq", "bigram_logfreq", "trigram_logfreq",
             "pos_ambig"))
```




Plotting all variables
---------------------

```{r, fig.width=12, fig.height=10}
ggplot(stiml, aes(x = category, y = value, colour = category)) +
  geom_boxplot() +
  facet_wrap(~ var, scales = "free_y")
```

Convenience function for plotting

```{r}
compar_plot <- function(df) {
  
}
```

